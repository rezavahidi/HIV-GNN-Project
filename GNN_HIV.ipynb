{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388b5d10",
   "metadata": {},
   "source": [
    "# GNN project using HIV dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bf19fb",
   "metadata": {},
   "source": [
    "## Get Data and Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aed6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import deepchem as dc\n",
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd175eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 103-104: truncated \\UXXXXXXXX escape (234719960.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m\u001b[0m\n\u001b[1;33m    graph_df.head() \"\"\"\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 103-104: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import deepchem as dc\n",
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\"\"\"\"\n",
    "# read dataset\n",
    "\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\rezav\\\\OneDrive\\\\Desktop\\\\data\\\\HIV_train.csv\")\n",
    "\"C:\\Users\\rezav\\OneDrive\\Desktop\\data\"\n",
    "# convert smiles string to RdKit format and extract node features and edge index using deepchem lib\n",
    "G = {\n",
    "    \"node_features\" : [],\n",
    "    \"edge_index\" : [],\n",
    "    \"label\" : []\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    mol = Chem.MolFromSmiles(dataset.iloc[i][\"smiles\"])\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "    f = featurizer._featurize(mol)\n",
    "    G[\"node_features\"].append(f.node_features)\n",
    "    G[\"edge_index\"].append(f.edge_index)\n",
    "    G[\"label\"].append(dataset.iloc[i][\"HIV_active\"])\n",
    "\n",
    "graph_df = pd.DataFrame(data=G)\n",
    "\n",
    "graph_df.head() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57986865",
   "metadata": {},
   "source": [
    "## under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc9e1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"C:\\\\Users\\\\rezav\\\\OneDrive\\\\Desktop\\\\data\\\\\"\n",
    "\n",
    "dataset = pd.read_csv(root + \"HIV.csv\")\n",
    "\n",
    "#under-sampling\n",
    "        \n",
    "positive = dataset[dataset['HIV_active']==1]\n",
    "negative = dataset[dataset['HIV_active']==0]\n",
    "negative = negative.sample(n=len(positive), random_state=101)\n",
    "dataset = pd.concat([positive,negative],axis=0)\n",
    "        \n",
    "#split to train, test\n",
    "        \n",
    "train, test = train_test_split(dataset , test_size=0.3, random_state=42, shuffle = True)\n",
    "\n",
    "train.to_csv(root + \"raw\\\\HIV_train.csv\", index = False)\n",
    "test.to_csv(root + \"raw\\\\HIV_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffee608",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c89491ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, download_url, Data\n",
    "\n",
    "\n",
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, test, filename, transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.test = test\n",
    "        self.filename = filename\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return self.filename\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return \"no.pt\"\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        self.data = pd.read_csv(self.raw_paths[0])\n",
    "        \n",
    "        idx = 0\n",
    "        \n",
    "        for index, x in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
    "            \n",
    "            #get smiles code and call featurizer\n",
    "            \n",
    "            mol = Chem.MolFromSmiles(x[\"smiles\"])\n",
    "            featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "            f = featurizer._featurize(mol)\n",
    "            \n",
    "            # get graph properties\n",
    "            \n",
    "            node_features = torch.tensor(f.node_features)\n",
    "            edge_index = torch.tensor(f.edge_index)\n",
    "            edge_features = torch.tensor(f.edge_features)\n",
    "            label = torch.tensor(np.asarray([x[\"HIV_active\"]]), dtype=torch.int64)\n",
    "        \n",
    "            data = Data(x = node_features,\n",
    "                        edge_index = edge_index,\n",
    "                        edge_attr = edge_features,\n",
    "                        y = label,\n",
    "                        smiles = x[\"smiles\"])\n",
    "\n",
    "            if self.test:\n",
    "                torch.save(data, osp.join(self.processed_dir, f'data_test_{idx}.pt'))\n",
    "            else:\n",
    "                torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "            idx += 1\n",
    "            \n",
    "    def len(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def get(self, idx):\n",
    "        if self.test:\n",
    "            data = torch.load(os.path.join(self.processed_dir, \n",
    "                                 f'data_test_{idx}.pt'))\n",
    "        else:\n",
    "            data = torch.load(os.path.join(self.processed_dir, \n",
    "                                 f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b523f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d03e06ec",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62dba867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      " 28%|██████████████████████▏                                                        | 502/1789 [00:06<00:14, 91.64it/s][08:29:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:29:09] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1789/1789 [00:24<00:00, 72.83it/s]\n",
      "Done!\n",
      "Processing...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 767/767 [00:11<00:00, 68.47it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "   \n",
    "\n",
    "#define dataset\n",
    "\n",
    "train_ds = MyOwnDataset(root, False, \"HIV_train.csv\")\n",
    "test_ds = MyOwnDataset(root, True, \"HIV_test.csv\")\n",
    "\n",
    "# define data loader\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aed3f6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c586cd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (conv1): GATConv(30, 128, heads=1)\n",
      "  (conv2): GATConv(128, 256, heads=1)\n",
      "  (conv3): GATConv(256, 128, heads=1)\n",
      "  (conv4): GATConv(128, 64, heads=1)\n",
      "  (lin1): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (lin2): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, GATv2Conv, TransformerConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_channels, conv, conv_params={}):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        \n",
    "        self.conv1 = conv(\n",
    "            30, 128)\n",
    "        \n",
    "        self.conv2 = conv(\n",
    "            128, 256)\n",
    "        \n",
    "        self.conv3 = conv(\n",
    "            256, 128)\n",
    "        \n",
    "        self.conv4 = conv(\n",
    "            128, 64)\n",
    "        \n",
    "        self.lin1 = Linear(64, 16)\n",
    "        self.lin2 = Linear(16, 1)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch = None,  edge_col = None):\n",
    "        \n",
    "        # Node embedding \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = x.relu()\n",
    "        # Readout layer\n",
    "        batch = torch.zeros(x.shape[0],dtype=int) if batch is None else batch\n",
    "        x = global_mean_pool(x, batch)\n",
    "        \n",
    "        # Final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "model = GNN(30, 16, GATConv)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff6866",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b79d3b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2721]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1) to match target batch_size (32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (32)."
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for data in train_dataloader:\n",
    "    prd = model(data.x.float(), data.edge_index)\n",
    "    optimizer.zero_grad()\n",
    "    print(prd)\n",
    "    print(data.x)\n",
    "    print(data.y)\n",
    "    loss = criterion(prd, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()\n",
    "    preds = prd.argmax(dim=1)\n",
    "    correct += (preds == Y).sum().item()\n",
    "    acc = 0\n",
    "    for x in range(len(preds)):\n",
    "        if preds[x] == y[x]:\n",
    "            acc += 1\n",
    "    acc /= len(y)\n",
    "    train_losses.append(loss)\n",
    "    train_accs.append(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563fb80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"train loss\")\n",
    "plt.plot(train_losses)\n",
    "plt.show()\n",
    "plt.title(\"train accuracy\")\n",
    "plt.plot(train_accs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba87d1",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ade4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "real = []\n",
    "prd = []\n",
    "\n",
    "\n",
    "for data in test_dataloader:\n",
    "    preds = []\n",
    "    for features, target in data:\n",
    "        out = model(features[0], features[1])\n",
    "        preds.append(out)\n",
    "        real.append(target)\n",
    "    preds = np.argmax(prd, axis=1)\n",
    "    prd = prd + preds\n",
    "    acc = 0\n",
    "    for x in range(len(preds)):\n",
    "        if preds[x] == real[x]:\n",
    "            acc += 1\n",
    "    acc /= len(real)\n",
    "    accuracy += acc\n",
    "    train_accs.append(acc)\n",
    "    \n",
    "print(\"accuracy: \" + accuracy_score(real, prd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
